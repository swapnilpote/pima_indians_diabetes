{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Outcome.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset.iloc[:, 0:8].values\n",
    "y = dataset.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,\n",
       "        6.270e-01, 5.000e+01],\n",
       "       [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,\n",
       "        3.510e-01, 3.100e+01],\n",
       "       [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,\n",
       "        6.720e-01, 3.200e+01],\n",
       "       [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,\n",
       "        1.670e-01, 2.100e+01],\n",
       "       [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,\n",
       "        2.288e+00, 3.300e+01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 691 samples, validate on 77 samples\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.5942 - acc: 0.6498 - val_loss: 0.6026 - val_acc: 0.6623\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5931 - acc: 0.6498 - val_loss: 0.6011 - val_acc: 0.6623\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5924 - acc: 0.6498 - val_loss: 0.6016 - val_acc: 0.6623\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5917 - acc: 0.6498 - val_loss: 0.6021 - val_acc: 0.6623\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 40us/step - loss: 0.5923 - acc: 0.6498 - val_loss: 0.6042 - val_acc: 0.6623\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5917 - acc: 0.6498 - val_loss: 0.6016 - val_acc: 0.6623\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5919 - acc: 0.6498 - val_loss: 0.6010 - val_acc: 0.6623\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5913 - acc: 0.6498 - val_loss: 0.6009 - val_acc: 0.6623\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.5917 - acc: 0.6498 - val_loss: 0.5995 - val_acc: 0.6623\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5910 - acc: 0.6498 - val_loss: 0.6008 - val_acc: 0.6623\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5910 - acc: 0.6498 - val_loss: 0.6007 - val_acc: 0.6623\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5908 - acc: 0.6498 - val_loss: 0.6009 - val_acc: 0.6623\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5910 - acc: 0.6498 - val_loss: 0.6021 - val_acc: 0.6623\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5916 - acc: 0.6498 - val_loss: 0.6017 - val_acc: 0.6623\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5897 - acc: 0.6498 - val_loss: 0.6004 - val_acc: 0.6623\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5899 - acc: 0.6498 - val_loss: 0.5996 - val_acc: 0.6623\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5911 - acc: 0.6498 - val_loss: 0.5977 - val_acc: 0.6623\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5899 - acc: 0.6498 - val_loss: 0.6010 - val_acc: 0.6623\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5889 - acc: 0.6498 - val_loss: 0.6006 - val_acc: 0.6623\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5887 - acc: 0.6498 - val_loss: 0.6011 - val_acc: 0.6623\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5888 - acc: 0.6498 - val_loss: 0.5994 - val_acc: 0.6623\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5894 - acc: 0.6498 - val_loss: 0.6012 - val_acc: 0.6623\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.5927 - acc: 0.6498 - val_loss: 0.5984 - val_acc: 0.6623\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.5888 - acc: 0.6498 - val_loss: 0.6018 - val_acc: 0.6623\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.5870 - acc: 0.6498 - val_loss: 0.5970 - val_acc: 0.6623\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5879 - acc: 0.6498 - val_loss: 0.5994 - val_acc: 0.6623\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5859 - acc: 0.6498 - val_loss: 0.6025 - val_acc: 0.6623\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.5856 - acc: 0.6498 - val_loss: 0.6015 - val_acc: 0.6623\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.5863 - acc: 0.6498 - val_loss: 0.6007 - val_acc: 0.6623\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5852 - acc: 0.6498 - val_loss: 0.6003 - val_acc: 0.6623\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5857 - acc: 0.6498 - val_loss: 0.5995 - val_acc: 0.6623\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5867 - acc: 0.6498 - val_loss: 0.6010 - val_acc: 0.6623\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.5880 - acc: 0.6498 - val_loss: 0.6041 - val_acc: 0.6623\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.5875 - acc: 0.6498 - val_loss: 0.6006 - val_acc: 0.6623\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.5841 - acc: 0.6498 - val_loss: 0.6022 - val_acc: 0.6623\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5844 - acc: 0.6498 - val_loss: 0.6040 - val_acc: 0.6623\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5855 - acc: 0.6498 - val_loss: 0.5999 - val_acc: 0.6623\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5837 - acc: 0.6498 - val_loss: 0.6012 - val_acc: 0.6623\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5843 - acc: 0.6498 - val_loss: 0.6039 - val_acc: 0.6623\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5862 - acc: 0.6498 - val_loss: 0.5999 - val_acc: 0.6623\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5841 - acc: 0.6498 - val_loss: 0.6014 - val_acc: 0.6623\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.5835 - acc: 0.6498 - val_loss: 0.6024 - val_acc: 0.6623\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5830 - acc: 0.6498 - val_loss: 0.5992 - val_acc: 0.6623\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.5851 - acc: 0.6498 - val_loss: 0.6018 - val_acc: 0.6623\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5828 - acc: 0.6498 - val_loss: 0.5983 - val_acc: 0.6623\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 68us/step - loss: 0.5829 - acc: 0.6498 - val_loss: 0.6016 - val_acc: 0.6623\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.5821 - acc: 0.6498 - val_loss: 0.6036 - val_acc: 0.6623\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 61us/step - loss: 0.5824 - acc: 0.6498 - val_loss: 0.6009 - val_acc: 0.6623\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 71us/step - loss: 0.5820 - acc: 0.6498 - val_loss: 0.5993 - val_acc: 0.6623\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.5812 - acc: 0.6498 - val_loss: 0.6004 - val_acc: 0.6623\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 74us/step - loss: 0.5815 - acc: 0.6498 - val_loss: 0.5990 - val_acc: 0.6623\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 79us/step - loss: 0.5839 - acc: 0.6498 - val_loss: 0.6013 - val_acc: 0.6623\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 78us/step - loss: 0.5828 - acc: 0.6498 - val_loss: 0.5982 - val_acc: 0.6623\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.5836 - acc: 0.6498 - val_loss: 0.6020 - val_acc: 0.6623\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 78us/step - loss: 0.5823 - acc: 0.6498 - val_loss: 0.5993 - val_acc: 0.6623\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 66us/step - loss: 0.5815 - acc: 0.6498 - val_loss: 0.6042 - val_acc: 0.6623\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 98us/step - loss: 0.5813 - acc: 0.6498 - val_loss: 0.6007 - val_acc: 0.6623\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.5844 - acc: 0.6498 - val_loss: 0.6021 - val_acc: 0.6623\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5825 - acc: 0.6498 - val_loss: 0.5987 - val_acc: 0.6623\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5831 - acc: 0.6498 - val_loss: 0.6063 - val_acc: 0.6623\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 46us/step - loss: 0.5814 - acc: 0.6498 - val_loss: 0.6002 - val_acc: 0.6623\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5800 - acc: 0.6498 - val_loss: 0.6013 - val_acc: 0.6623\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5800 - acc: 0.6498 - val_loss: 0.6008 - val_acc: 0.6623\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.5804 - acc: 0.6498 - val_loss: 0.5989 - val_acc: 0.6623\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5801 - acc: 0.6498 - val_loss: 0.5982 - val_acc: 0.6623\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5796 - acc: 0.6498 - val_loss: 0.5971 - val_acc: 0.6623\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 60us/step - loss: 0.5796 - acc: 0.6498 - val_loss: 0.5980 - val_acc: 0.6623\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5796 - acc: 0.6498 - val_loss: 0.5981 - val_acc: 0.6623\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5807 - acc: 0.6498 - val_loss: 0.5978 - val_acc: 0.6623\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5809 - acc: 0.6498 - val_loss: 0.5988 - val_acc: 0.6623\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5800 - acc: 0.6498 - val_loss: 0.5964 - val_acc: 0.6623\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.5786 - acc: 0.6498 - val_loss: 0.5972 - val_acc: 0.6623\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 63us/step - loss: 0.5799 - acc: 0.6498 - val_loss: 0.5972 - val_acc: 0.6623\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5793 - acc: 0.6498 - val_loss: 0.6000 - val_acc: 0.6623\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.5784 - acc: 0.6498 - val_loss: 0.5967 - val_acc: 0.6623\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5789 - acc: 0.6498 - val_loss: 0.5934 - val_acc: 0.6623\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5815 - acc: 0.6498 - val_loss: 0.5956 - val_acc: 0.6623\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5809 - acc: 0.6498 - val_loss: 0.5944 - val_acc: 0.6623\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5780 - acc: 0.6498 - val_loss: 0.5963 - val_acc: 0.6623\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5777 - acc: 0.6498 - val_loss: 0.5966 - val_acc: 0.6623\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5780 - acc: 0.6498 - val_loss: 0.5954 - val_acc: 0.6623\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5798 - acc: 0.6498 - val_loss: 0.5983 - val_acc: 0.6623\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5775 - acc: 0.6498 - val_loss: 0.5955 - val_acc: 0.6623\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.5786 - acc: 0.6498 - val_loss: 0.5941 - val_acc: 0.6623\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.5773 - acc: 0.6498 - val_loss: 0.5981 - val_acc: 0.6623\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.5778 - acc: 0.6498 - val_loss: 0.5945 - val_acc: 0.6623\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5766 - acc: 0.6498 - val_loss: 0.5954 - val_acc: 0.6623\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5762 - acc: 0.6498 - val_loss: 0.5929 - val_acc: 0.6623\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5769 - acc: 0.6498 - val_loss: 0.5947 - val_acc: 0.6623\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5768 - acc: 0.6498 - val_loss: 0.5975 - val_acc: 0.6623\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5758 - acc: 0.6498 - val_loss: 0.5952 - val_acc: 0.6623\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5775 - acc: 0.6498 - val_loss: 0.5992 - val_acc: 0.6494\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5769 - acc: 0.6512 - val_loss: 0.5902 - val_acc: 0.6623\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5754 - acc: 0.6527 - val_loss: 0.5952 - val_acc: 0.6494\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5765 - acc: 0.6512 - val_loss: 0.5952 - val_acc: 0.6494\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5745 - acc: 0.6527 - val_loss: 0.5957 - val_acc: 0.6494\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5744 - acc: 0.6527 - val_loss: 0.6015 - val_acc: 0.6494\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 57us/step - loss: 0.5751 - acc: 0.6570 - val_loss: 0.6143 - val_acc: 0.6494\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5740 - acc: 0.6614 - val_loss: 0.6165 - val_acc: 0.6494\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5780 - acc: 0.6628 - val_loss: 0.6073 - val_acc: 0.6494\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5792 - acc: 0.6614 - val_loss: 0.6170 - val_acc: 0.6494\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5734 - acc: 0.6643 - val_loss: 0.6189 - val_acc: 0.6494\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5706 - acc: 0.6614 - val_loss: 0.6106 - val_acc: 0.6494\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5739 - acc: 0.6599 - val_loss: 0.6115 - val_acc: 0.6494\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5727 - acc: 0.6599 - val_loss: 0.6131 - val_acc: 0.6494\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5716 - acc: 0.6614 - val_loss: 0.6111 - val_acc: 0.6494\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.5715 - acc: 0.6614 - val_loss: 0.6024 - val_acc: 0.6494\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5716 - acc: 0.6585 - val_loss: 0.6044 - val_acc: 0.6494\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5697 - acc: 0.6614 - val_loss: 0.6141 - val_acc: 0.6623\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 46us/step - loss: 0.5700 - acc: 0.6614 - val_loss: 0.6037 - val_acc: 0.6494\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5707 - acc: 0.6599 - val_loss: 0.6073 - val_acc: 0.6494\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5683 - acc: 0.6686 - val_loss: 0.6129 - val_acc: 0.6623\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5703 - acc: 0.6614 - val_loss: 0.6051 - val_acc: 0.6494\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5691 - acc: 0.6657 - val_loss: 0.6091 - val_acc: 0.6494\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5675 - acc: 0.6643 - val_loss: 0.6090 - val_acc: 0.6494\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 56us/step - loss: 0.5672 - acc: 0.6671 - val_loss: 0.6097 - val_acc: 0.6494\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5686 - acc: 0.6599 - val_loss: 0.6052 - val_acc: 0.6494\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.5722 - acc: 0.6570 - val_loss: 0.5959 - val_acc: 0.6494\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 45us/step - loss: 0.5719 - acc: 0.6570 - val_loss: 0.5997 - val_acc: 0.6494\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5690 - acc: 0.6599 - val_loss: 0.6016 - val_acc: 0.6494\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 50us/step - loss: 0.5671 - acc: 0.6671 - val_loss: 0.6073 - val_acc: 0.6623\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5676 - acc: 0.6614 - val_loss: 0.6063 - val_acc: 0.6494\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5683 - acc: 0.6657 - val_loss: 0.6059 - val_acc: 0.6494\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 59us/step - loss: 0.5664 - acc: 0.6614 - val_loss: 0.6112 - val_acc: 0.6623\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5718 - acc: 0.6556 - val_loss: 0.6043 - val_acc: 0.6494\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5715 - acc: 0.6599 - val_loss: 0.6088 - val_acc: 0.6494\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5715 - acc: 0.6657 - val_loss: 0.6069 - val_acc: 0.6494\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5643 - acc: 0.6643 - val_loss: 0.6035 - val_acc: 0.6494\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5725 - acc: 0.6614 - val_loss: 0.6060 - val_acc: 0.6494\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5697 - acc: 0.6671 - val_loss: 0.6092 - val_acc: 0.6623\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 44us/step - loss: 0.5669 - acc: 0.6585 - val_loss: 0.5988 - val_acc: 0.6494\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 42us/step - loss: 0.5697 - acc: 0.6599 - val_loss: 0.5933 - val_acc: 0.6494\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 47us/step - loss: 0.5696 - acc: 0.6599 - val_loss: 0.5963 - val_acc: 0.6494\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 43us/step - loss: 0.5669 - acc: 0.6671 - val_loss: 0.6068 - val_acc: 0.6494\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5644 - acc: 0.6643 - val_loss: 0.6090 - val_acc: 0.6494\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5658 - acc: 0.6657 - val_loss: 0.6032 - val_acc: 0.6494\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5662 - acc: 0.6628 - val_loss: 0.6055 - val_acc: 0.6494\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 58us/step - loss: 0.5673 - acc: 0.6643 - val_loss: 0.6029 - val_acc: 0.6494\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5648 - acc: 0.6643 - val_loss: 0.6008 - val_acc: 0.6494\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 53us/step - loss: 0.5660 - acc: 0.6643 - val_loss: 0.6011 - val_acc: 0.6494\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 62us/step - loss: 0.5648 - acc: 0.6671 - val_loss: 0.6022 - val_acc: 0.6494\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 51us/step - loss: 0.5642 - acc: 0.6657 - val_loss: 0.6058 - val_acc: 0.6494\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 48us/step - loss: 0.5652 - acc: 0.6671 - val_loss: 0.6037 - val_acc: 0.6494\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5676 - acc: 0.6643 - val_loss: 0.5999 - val_acc: 0.6494\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5655 - acc: 0.6671 - val_loss: 0.6045 - val_acc: 0.6494\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 54us/step - loss: 0.5645 - acc: 0.6686 - val_loss: 0.6027 - val_acc: 0.6494\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 50us/step - loss: 0.5664 - acc: 0.6614 - val_loss: 0.6030 - val_acc: 0.6494\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 55us/step - loss: 0.5639 - acc: 0.6715 - val_loss: 0.6054 - val_acc: 0.6494\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 52us/step - loss: 0.5634 - acc: 0.6686 - val_loss: 0.6036 - val_acc: 0.6494\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 49us/step - loss: 0.5633 - acc: 0.6628 - val_loss: 0.6043 - val_acc: 0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118797978>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 150, batch_size = 64, validation_data = [X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
